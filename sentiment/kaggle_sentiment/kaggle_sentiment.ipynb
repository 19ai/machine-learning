{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('http://fonts.googleapis.com/css?family=Source+Code+Pro');\n",
       "@import url('http://fonts.googleapis.com/css?family=Vollkorn');\n",
       "@import url('http://fonts.googleapis.com/css?family=Arimo');\n",
       "@import url('http://fonts.googleapis.com/css?family=Fira_sans');\n",
       "\n",
       "    div.cell{\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.text_cell code {\n",
       "        background: transparent;\n",
       "        color: #000000;\n",
       "        font-weight: 600;\n",
       "        font-size: 12pt;\n",
       "        font-style: bold;\n",
       "        font-family:  'Source Code Pro', Consolas, monocco, monospace;\n",
       "   }\n",
       "    h1 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "\t}\n",
       "\t\n",
       "    div.input_area {\n",
       "        background: #F6F6F9;\n",
       "        border: 1px solid #586e75;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 30pt;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h2 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "        text-align: left;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200;\n",
       "        font-size: 16pt;\n",
       "        font-style: italic;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1.5em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h3 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200;\n",
       "        font-size: 14pt;\n",
       "        line-height: 100%;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 2em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    h4 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-weight: 100;\n",
       "        font-size: 14pt;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    h5 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200;\n",
       "        font-style: normal;\n",
       "        color: #1d3b84;\n",
       "        font-size: 16pt;\n",
       "        margin-bottom: 0em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Fira sans', verdana,arial,sans-serif;\n",
       "        line-height: 125%;\n",
       "        font-size: 115%;\n",
       "        text-align:justify;\n",
       "        text-justify:inter-word;\n",
       "    }\n",
       "    div.output_subarea.output_text.output_pyout {\n",
       "        overflow-x: auto;\n",
       "        overflow-y: scroll;\n",
       "        max-height: 50000px;\n",
       "    }\n",
       "    div.output_subarea.output_stream.output_stdout.output_text {\n",
       "        overflow-x: auto;\n",
       "        overflow-y: scroll;\n",
       "        max-height: 50000px;\n",
       "    }\n",
       "    div.output_wrapper{\n",
       "        margin-top:0.2em;\n",
       "        margin-bottom:0.2em;\n",
       "}\n",
       "\n",
       "    code{\n",
       "      font-size: 70%;\n",
       "    }\n",
       "    .rendered_html code{\n",
       "    background-color: transparent;\n",
       "    }\n",
       "    ul{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li li{\n",
       "        padding-left: 0.2em; \n",
       "        margin-bottom: 0.2em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    ol{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ol li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "    .rendered_html :hover {\n",
       "       text-decoration: none; \n",
       "    }\n",
       "    .rendered_html :visited {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :focus {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :active {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    } \n",
       "    hr {\n",
       "      color: #f3f3f3;\n",
       "      background-color: #f3f3f3;\n",
       "      height: 1px;\n",
       "    }\n",
       "    blockquote{\n",
       "      display:block;\n",
       "      background: #fcfcfc;\n",
       "      border-left: 5px solid #c76c0c;\n",
       "      font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "      width:680px;\n",
       "      padding: 10px 10px 10px 10px;\n",
       "      text-align:justify;\n",
       "      text-justify:inter-word;\n",
       "      }\n",
       "      blockquote p {\n",
       "        margin-bottom: 0;\n",
       "        line-height: 125%;\n",
       "        font-size: 100%;\n",
       "      }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir('../../notebook_format')\n",
    "from formats import load_style\n",
    "load_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Kaggle knowledge competition: movie review sentiment analysis. [homepage](https://www.kaggle.com/c/word2vec-nlp-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv( 'labeledTrainData.tsv', delimiter = '\\t' )\n",
    "test  = pd.read_csv( 'testData.tsv', delimiter = '\\t' )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove tags or markup (e.g. <br> <\\br> )\n",
    "train['review'] = train['review'].apply( lambda s: BeautifulSoup(s).get_text() )\n",
    "test['review']  = test['review'].apply( lambda s: BeautifulSoup(s).get_text() )\n",
    "\n",
    "# extract the training and testing's data/label\n",
    "X_train = train['review']\n",
    "y_train = train['sentiment']\n",
    "X_test  = test['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Try \n",
    "\n",
    "Use the most simplest approach: remove english stopwords, bag of words + default logistic regression and naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert both sets' text column to document-term matrix\n",
    "vect1 = CountVectorizer( stop_words = 'english' )\n",
    "X_train_dtm = vect1.fit_transform(X_train)\n",
    "X_test_dtm  = vect1.transform(X_test)\n",
    "\n",
    "# train the models\n",
    "nb = MultinomialNB()\n",
    "nb.fit( X_train_dtm, y_train )\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit( X_train_dtm, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# naive bayes 0.89415\n",
    "pred_nb = nb.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred_nb })\n",
    "output.to_csv( 'nb.csv', index = False )\n",
    "\n",
    "# logistic regression 0.92943\n",
    "pred_logreg = logreg.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred_logreg })\n",
    "output.to_csv( 'logreg.csv', index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Try\n",
    "\n",
    "Include n-gram (1 and 2-gram to be exact), stemming (e.g. running will be converted to run) and use cross validation to determine the best regularization for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    \"\"\"pass into the tokenizer argument of Count\"\"\"\n",
    "    stemmed = [ porter.stem(word) for word in text.split() ]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model( X_train, y_train ):\n",
    "    \"\"\"\n",
    "    Pass in the training data and its label, train a logistic regression and \n",
    "    naive bayes model, where 10-fold cross validation is used to determine \n",
    "    the best regularization for logistic regression\n",
    "    \n",
    "    TODO: this should probably return a dictionary or a list or a namedtuple\n",
    "    of trained models\n",
    "    \"\"\"\n",
    "    logreg = LogisticRegression()\n",
    "    param_grid = { 'C': [ 0.001, 0.01, 0.1, 1, 10, 25 ] }\n",
    "    grid_logreg = GridSearchCV( \n",
    "        logreg, \n",
    "        param_grid = param_grid, \n",
    "        cv = 10,\n",
    "        scoring = 'roc_auc',\n",
    "        n_jobs = -1,\n",
    "        verbose = 1\n",
    "    )\n",
    "    grid_logreg.fit( X_train, y_train )\n",
    "    \n",
    "    nb = MultinomialNB()\n",
    "    nb.fit( X_train, y_train )\n",
    "    \n",
    "    return grid_logreg, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer( \n",
    "    stop_words = 'english', \n",
    "    tokenizer = tokenizer_porter, \n",
    "    ngram_range = ( 1, 2 ),\n",
    "    min_df = 2\n",
    ")\n",
    "X_train_dtm = vect2.fit_transform(X_train)\n",
    "X_test_dtm  = vect2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "grid_logreg1, nb1 = create_model( X_train = X_train_dtm, y_train = y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948118976\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_logreg1.best_score_)\n",
    "print(grid_logreg1.best_params_)\n",
    "\n",
    "# 0.94474\n",
    "pred_logreg = grid_logreg1.best_estimator_.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred_logreg })\n",
    "output.to_csv( 'logreg.csv', index = False )\n",
    "\n",
    "# 0.92292\n",
    "pred2 = nb1.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred2 })\n",
    "output.to_csv( 'nb.csv', index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Try\n",
    "\n",
    "Use tf-idf instead of bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_vect1 = TfidfVectorizer( \n",
    "    stop_words = 'english', \n",
    "    tokenizer = tokenizer_porter, \n",
    "    ngram_range = ( 1, 2 ),\n",
    "    min_df = 2\n",
    ")\n",
    "X_train_dtm = tf_vect1.fit_transform(X_train)\n",
    "X_test_dtm  = tf_vect1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   32.1s finished\n"
     ]
    }
   ],
   "source": [
    "grid_logreg2, nb2 = create_model( X_train = X_train_dtm, y_train = y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958878528\n",
      "{'C': 25}\n"
     ]
    }
   ],
   "source": [
    "print(grid_logreg2.best_score_)\n",
    "print(grid_logreg2.best_params_)\n",
    "\n",
    "# 0.95386\n",
    "pred1 = grid_logreg2.best_estimator_.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred1 })\n",
    "output.to_csv( 'logreg.csv', index = False )\n",
    "\n",
    "# 0.93842\n",
    "pred2 = nb2.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred2 })\n",
    "output.to_csv( 'nb.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_probabilities( models, X_test ):\n",
    "    \"\"\"\n",
    "    For each model, predict the probability of the test set\n",
    "    and store the result in one single dataframe\n",
    "    TODO : make it work with models from other commonly used library\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        already fitted models\n",
    "        \n",
    "    X_test : \n",
    "        test data of the fitted models\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    predictions : DataFrame\n",
    "        each column is the predicted probability of the test data for each model\n",
    "    \"\"\"\n",
    "    col_names = []\n",
    "    predictions = np.zeros( ( X_test.shape[0], len(models) ) )   \n",
    "    \n",
    "    for index, model in enumerate(models):\n",
    "        \n",
    "        # if it's a sklearn's CV model, search deeper for model name\n",
    "        # and it's best estimated parameter\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        if model_name in ( 'GridSearchCV', 'RandomizedSearchCV' ):\n",
    "            best_model = model.best_estimator_\n",
    "            pred = best_model.predict_proba(X_test)[ :, 1 ]\n",
    "            \n",
    "            # obtain the best parameter obtained by the grid search\n",
    "            strings = []\n",
    "            params = model.best_params_           \n",
    "            for key, value in params.items():\n",
    "                string = str(key) + '-' + str(value)\n",
    "                strings.append(string)\n",
    "            \n",
    "            # concatenate the model's name and the best parameter\n",
    "            param_strings = '_'.join(strings)\n",
    "            col_name = best_model.__class__.__name__ + '_' + param_strings             \n",
    "        else:\n",
    "            pred = model.predict_proba(X_test)[ :, 1 ]\n",
    "            col_name = model_name\n",
    "        \n",
    "        predictions[ :, index ] = pred\n",
    "        col_names.append(col_name)\n",
    "    \n",
    "    predictions = pd.DataFrame( predictions, columns = col_names )    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [ grid_logreg2, nb2 ]\n",
    "predictions = predict_probabilities( models = models, X_test = X_test_dtm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manually weighted average : 0.95508\n",
    "pred = np.average( predictions.values, axis = 1, weights = ( 0.7, 0.3 ) )\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred })\n",
    "output.to_csv( 'test.csv', index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding More Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')\n",
    "\n",
    "# retain only the positive and negative text\n",
    "sub_tweets = tweets[ tweets['airline_sentiment'].isin( [ 'positive', 'negative' ] ) ]\n",
    "sub_tweets = sub_tweets[[ 'text', 'airline_sentiment' ]]\n",
    "\n",
    "# change the column and output label to match the original data\n",
    "sub_tweets.columns = [ 'review', 'sentiment' ]\n",
    "sub_tweets['sentiment'] = sub_tweets['sentiment'].map({ 'positive': 1, 'negative': 0 })\n",
    "sub_tweets.reset_index( inplace = True, drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_hashtag(text):\n",
    "    clean_text = [ t for t in text.split() if not t.startswith('@') ]\n",
    "    clean_text = ' '.join(clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_tweets['review'] = sub_tweets['review'].apply(remove_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train[['review']]\n",
    "y_train = train[['sentiment']]\n",
    "X_train = X_train.append(sub_tweets[['review']])\n",
    "y_train = y_train.append(sub_tweets[['sentiment']])\n",
    "\n",
    "X_train = X_train['review']\n",
    "y_train = y_train['sentiment']\n",
    "X_test  = test['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_dtm = tf_vect1.fit_transform(X_train)\n",
    "X_test_dtm  = tf_vect1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   32.6s finished\n"
     ]
    }
   ],
   "source": [
    "grid_logreg3, nb3 = create_model( X_train = X_train_dtm, y_train = y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [ grid_logreg3, nb3 ]\n",
    "predictions = predict_probabilities( models = models, X_test = X_test_dtm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred1 = grid_logreg3.best_estimator_.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred1 })\n",
    "output.to_csv( 'logreg.csv', index = False )\n",
    "\n",
    "# 0.93842\n",
    "pred2 = nb3.predict_proba(X_test_dtm)[ :, 1 ]\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred2 })\n",
    "output.to_csv( 'nb.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.average( predictions.values, axis = 1, weights = ( 0.7, 0.3 ) )\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred })\n",
    "output.to_csv( 'test.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Kaggle Use Google's Word2Vec for movie reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial)\n",
    "- [Blog on Natural Language Processing in a Kaggle Competition for Movie Reviews](https://jessesw.com/NLP-Movie-Reviews/)\n",
    "\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/forums/t/14966/post-competition-solutions\n",
    "\n",
    "https://github.com/mesnilgr/nbsvm\n",
    "\n",
    "https://github.com/vivekn/sentiment\n",
    "\n",
    "https://github.com/vsl9/Sentiment-Analysis-with-Convolutional-Networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
